{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2aa593c",
   "metadata": {},
   "source": [
    "## Machine learning module to multiply by 3\n",
    "\n",
    "- Simple model creation to test out various of Manipulations that are possible to do using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae026a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training f(5) = -2.676\n",
      "epoch 1: w = -0.563538 , loss = 92.551842 , inputs torch.Size([4, 1]) \n",
      "epoch 2501: w = 2.560971 , loss = 0.242266 , inputs torch.Size([4, 1]) \n",
      "epoch 5001: w = 2.636560 , loss = 0.189941 , inputs torch.Size([4, 1]) \n",
      "epoch 7501: w = 2.663431 , loss = 0.163532 , inputs torch.Size([4, 1]) \n",
      "epoch 10001: w = 2.687697 , loss = 0.140802 , inputs torch.Size([4, 1]) \n",
      "epoch 12501: w = 2.710221 , loss = 0.121231 , inputs torch.Size([4, 1]) \n",
      "epoch 15001: w = 2.731101 , loss = 0.104382 , inputs torch.Size([4, 1]) \n",
      "epoch 17501: w = 2.750487 , loss = 0.089875 , inputs torch.Size([4, 1]) \n",
      "epoch 20001: w = 2.768458 , loss = 0.077386 , inputs torch.Size([4, 1]) \n",
      "epoch 22501: w = 2.785142 , loss = 0.066633 , inputs torch.Size([4, 1]) \n",
      "epoch 25001: w = 2.800622 , loss = 0.057374 , inputs torch.Size([4, 1]) \n",
      "epoch 27501: w = 2.814993 , loss = 0.049402 , inputs torch.Size([4, 1]) \n",
      "epoch 30001: w = 2.828352 , loss = 0.042538 , inputs torch.Size([4, 1]) \n",
      "epoch 32501: w = 2.840678 , loss = 0.036631 , inputs torch.Size([4, 1]) \n",
      "epoch 35001: w = 2.852196 , loss = 0.031541 , inputs torch.Size([4, 1]) \n",
      "epoch 37501: w = 2.862806 , loss = 0.027162 , inputs torch.Size([4, 1]) \n",
      "epoch 40001: w = 2.872674 , loss = 0.023391 , inputs torch.Size([4, 1]) \n",
      "epoch 42501: w = 2.881849 , loss = 0.020143 , inputs torch.Size([4, 1]) \n",
      "epoch 45001: w = 2.890363 , loss = 0.017346 , inputs torch.Size([4, 1]) \n",
      "epoch 47501: w = 2.898253 , loss = 0.014938 , inputs torch.Size([4, 1]) \n",
      "epoch 50001: w = 2.905565 , loss = 0.012865 , inputs torch.Size([4, 1]) \n",
      "epoch 52501: w = 2.912349 , loss = 0.011080 , inputs torch.Size([4, 1]) \n",
      "epoch 55001: w = 2.918666 , loss = 0.009541 , inputs torch.Size([4, 1]) \n",
      "epoch 57501: w = 2.924558 , loss = 0.008217 , inputs torch.Size([4, 1]) \n",
      "epoch 60001: w = 2.929953 , loss = 0.007078 , inputs torch.Size([4, 1]) \n",
      "epoch 62501: w = 2.934974 , loss = 0.006096 , inputs torch.Size([4, 1]) \n",
      "epoch 65001: w = 2.939712 , loss = 0.005250 , inputs torch.Size([4, 1]) \n",
      "epoch 67501: w = 2.943974 , loss = 0.004523 , inputs torch.Size([4, 1]) \n",
      "epoch 70001: w = 2.948067 , loss = 0.003894 , inputs torch.Size([4, 1]) \n",
      "epoch 72501: w = 2.951732 , loss = 0.003356 , inputs torch.Size([4, 1]) \n",
      "epoch 75001: w = 2.955279 , loss = 0.002890 , inputs torch.Size([4, 1]) \n",
      "epoch 77501: w = 2.958436 , loss = 0.002489 , inputs torch.Size([4, 1]) \n",
      "epoch 80001: w = 2.961421 , loss = 0.002146 , inputs torch.Size([4, 1]) \n",
      "epoch 82501: w = 2.964234 , loss = 0.001847 , inputs torch.Size([4, 1]) \n",
      "epoch 85001: w = 2.966751 , loss = 0.001592 , inputs torch.Size([4, 1]) \n",
      "epoch 87501: w = 2.969137 , loss = 0.001372 , inputs torch.Size([4, 1]) \n",
      "epoch 90001: w = 2.971415 , loss = 0.001181 , inputs torch.Size([4, 1]) \n",
      "Prediction after training: f(5) = 14.941\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "X = torch.tensor([[1],[2],[3],[4]] , dtype=torch.float32)\n",
    "Y = torch.tensor([[3],[6],[9],[12]] , dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "X_test = torch.tensor([5] , dtype=torch.float32)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dimensions , output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dimensions,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size , output_size)\n",
    "\n",
    "#loss\n",
    "\n",
    "print(f'Prediction before training f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "n_itters = 90095\n",
    "learning_rate = 0.0001\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_itters):\n",
    "    # prediction = foreard pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "\n",
    "    #loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    #gradient dw = gradient(X,Y,y_pred)\n",
    "    l.backward()\n",
    "\n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    #zerro gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        if epoch%2500==0:\n",
    "            print(f'epoch {epoch + 1}: w = {w[0][0].item():3f} , loss = {l:8f} , inputs {X.shape} ')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "torch.save(model,'./storage/calculator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe701bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 multiply by 3 = \n",
      "42\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dimensions , output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dimensions,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "model = torch.load('./storage/calculator.model')\n",
    "model.eval()\n",
    "print('14 multiply by 3 = ')\n",
    "print(f'{model(torch.tensor([float(14)])).item():.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945272a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=open('./storage/in.csv','w')\n",
    "for i in range(0,871):\n",
    "    df.write(str(i) + ',' + str(i * 3))\n",
    "    df.write('\\n')\n",
    "df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8c02e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.]) tensor([0.])\n",
      "tensor([[749.],\n",
      "        [268.],\n",
      "        [687.],\n",
      "        [366.],\n",
      "        [231.],\n",
      "        [ 56.],\n",
      "        [568.],\n",
      "        [133.],\n",
      "        [725.],\n",
      "        [310.],\n",
      "        [343.],\n",
      "        [ 84.]]) tensor([[2247.],\n",
      "        [ 804.],\n",
      "        [2061.],\n",
      "        [1098.],\n",
      "        [ 693.],\n",
      "        [ 168.],\n",
      "        [1704.],\n",
      "        [ 399.],\n",
      "        [2175.],\n",
      "        [ 930.],\n",
      "        [1029.],\n",
      "        [ 252.]])\n",
      "871 218\n",
      "Prediction after training: f(5) = 15.000\n",
      "Prediction after training: f(10) = 30.000\n",
      "Prediction after training: f(1) = 3.000\n",
      "graph(%to_calc : Float(1, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %lin.bias : Float(1, strides=[1], requires_grad=1, device=cpu),\n",
      "      %6 : Float(1, 1, strides=[1, 1], requires_grad=0, device=cpu)):\n",
      "  %4 : Float(1, 1, 1, 1, strides=[1, 1, 1, 1], device=cpu) = onnx::MatMul(%to_calc, %6)\n",
      "  %calculated : Float(1, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%lin.bias, %4) # /opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:1847:0\n",
      "  return (%calculated)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##loss functions with Torch implemented\n",
    "# 1) Designe model (input , output size , forward pass)\n",
    "# 2) Construct Loss and Optimizer\n",
    "# 3) Training loop\n",
    "#   - Forward pass : Compute prediction\n",
    "#   - backward pass : gradients\n",
    "#     - update our weights\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "\n",
    "# 0) prepare data\n",
    "\n",
    "\n",
    "class CalcDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "\n",
    "        X_numpy, Y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "        self.x = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "        self.y = torch.from_numpy(Y_numpy.astype(np.float32))\n",
    "        self.n_samples = self.y.shape[0]\n",
    "\n",
    "        xy = np.loadtxt('./storage/in.csv' , delimiter=\",\",dtype=np.float32)\n",
    "        self.x = torch.from_numpy(xy[:,[0]])\n",
    "        self.y = torch.from_numpy(xy[:,[1]]) # n_samples 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index],self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset = CalcDataset()\n",
    "first_data = dataset[0]\n",
    "features,labels = first_data\n",
    "print(features,labels)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset , batch_size=12 , shuffle=True,num_workers=1)\n",
    "\n",
    "dataitter = iter(dataloader)\n",
    "data = dataitter.next()\n",
    "features,labels = data\n",
    "print(features,labels)\n",
    "\n",
    "# 1)model\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dimensions , output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dimensions,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size , output_size)\n",
    "\n",
    "#2) loss && optimizer\n",
    "learning_rate=0.01\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#def loss(y, y_predicted):\n",
    "#    print(y, y_predicted)\n",
    "#    exit()\n",
    "#    return ((y_predicted - y)**2).mean()\n",
    "#criterion = loss\n",
    "\n",
    "#optimizer = torch.optim.Adadelta(model.parameters() , lr=learning_rate)\n",
    "optimizer = torch.optim.Rprop(model.parameters() , lr=learning_rate) # [best]\n",
    "## fatal optimizer = torch.optim.SparseAdam(model.parameters() , lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters() , lr=learning_rate)\n",
    "\n",
    "#https://en.wikipedia.org/wiki/Rprop\n",
    "\n",
    "#training loop\n",
    "num_epoch = 100\n",
    "total_samples = len(dataset)\n",
    "n_itterations = math.ceil(total_samples/4)\n",
    "\n",
    "print(total_samples,n_itterations)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i , (inputs, labels) in enumerate(dataloader):\n",
    "\n",
    "        # prediction = foreard pass\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        # loss\n",
    "        l = criterion(labels, y_pred)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 150 == 0:\n",
    "            #epoch 5085: w = 2.946607 , loss = 0.004022 , inputs torch.Size([4, 1])\n",
    "            #epoch 2/2 , step 50/218 , inputs torch.Size([12, 1]) , loss =      nan\n",
    "\n",
    "            print(f'epoch {epoch+1}/{num_epoch} , step {i+1}/{n_itterations} , inputs {inputs.shape} , loss = {l:8f}')\n",
    "\n",
    "\n",
    "#plot\n",
    "predicted = model(labels).detach().numpy()\n",
    "\n",
    "\n",
    "X_test = torch.tensor([5] , dtype=torch.float32)\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n",
    "X_test = torch.tensor([10] , dtype=torch.float32)\n",
    "print(f'Prediction after training: f(10) = {model(X_test).item():.3f}')\n",
    "X_test = torch.tensor([1] , dtype=torch.float32)\n",
    "print(f'Prediction after training: f(1) = {model(X_test).item():.3f}')\n",
    "\n",
    "dummy_input = torch.randn(1,1,1,1)\n",
    "input_names = [ \"to_calc\" ]\n",
    "output_names = [ \"calculated\" ]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"storage/calculator_lin.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n",
    "# os.system('onnx-tf convert -i ./calculator.onnx -o ./calculator.pb')\n",
    "#tensorflowjs_converter  ./calculator.pb ./calculator.json\n",
    "\n",
    "plt.plot(inputs.numpy(),labels.numpy() , 'ro')\n",
    "plt.plot(inputs.numpy(),predicted,'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0684c46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into './storage/onnx-install'...\n",
      "remote: Enumerating objects: 6345, done.\u001b[K\n",
      "remote: Counting objects: 100% (294/294), done.\u001b[K\n",
      "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
      "remote: Total 6345 (delta 192), reused 235 (delta 156), pack-reused 6051\u001b[K\n",
      "Receiving objects: 100% (6345/6345), 1.97 MiB | 1.01 MiB/s, done.\n",
      "Resolving deltas: 100% (4917/4917), done.\n",
      "Obtaining file:///home/jovyan/work/notebooks/git_studies/calculator/storage/onnx-install\n",
      "Collecting onnx>=1.9.0\n",
      "  Downloading onnx-1.10.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 30.5 MB/s eta 0:00:01    |███████████████████▌            | 7.5 MB 30.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from onnx-tf==1.9.0) (5.4.1)\n",
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.14.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 34.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /opt/conda/lib/python3.9/site-packages (from onnx>=1.9.0->onnx-tf==1.9.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.9/site-packages (from onnx>=1.9.0->onnx-tf==1.9.0) (3.7.4.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from onnx>=1.9.0->onnx-tf==1.9.0) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.9/site-packages (from onnx>=1.9.0->onnx-tf==1.9.0) (1.19.5)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons, onnx, onnx-tf\n",
      "  Running setup.py develop for onnx-tf\n",
      "Successfully installed onnx-1.10.1 onnx-tf-1.9.0 tensorflow-addons-0.14.0 typeguard-2.13.0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/onnx/onnx-tensorflow.git ./storage/onnx-install &&\\\n",
    "    cd ./storage/onnx-install &&\\\n",
    "    pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b4757b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%actual_input_1 : Float(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %lin.bias : Float(1, strides=[1], requires_grad=1, device=cpu),\n",
      "      %6 : Float(1, 1, strides=[1, 1], requires_grad=0, device=cpu)):\n",
      "  %4 : Float(1, strides=[1], device=cpu) = onnx::MatMul(%actual_input_1, %6)\n",
      "  %output1 : Float(1, strides=[1], requires_grad=1, device=cpu) = onnx::Add(%lin.bias, %4) # /opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:1847:0\n",
      "  return (%output1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/notebooks/git_studies/calculator/storage/onnx-install/onnx_tf/backend.py:285: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  name = get_unique_suffix() + name if name[0] is \"_\" else name\n",
      "2021-10-11 14:51:15.013914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-11 14:51:15.013955: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-10-11 14:52:25,449 - onnx-tf - INFO - Start converting onnx pb to tf saved model\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/onnx-tf\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('onnx-tf', 'console_scripts', 'onnx-tf')())\n",
      "  File \"/home/jovyan/work/notebooks/git_studies/calculator/storage/onnx-install/onnx_tf/cli.py\", line 20, in main\n",
      "    return onnx_tf.converter.main(args[1:])\n",
      "  File \"/home/jovyan/work/notebooks/git_studies/calculator/storage/onnx-install/onnx_tf/converter.py\", line 21, in main\n",
      "    convert(**{k: v for k, v in vars(args).items() if v is not None})\n",
      "  File \"/home/jovyan/work/notebooks/git_studies/calculator/storage/onnx-install/onnx_tf/converter.py\", line 144, in convert\n",
      "    onnx_model = onnx.load(infile)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/onnx/__init__.py\", line 120, in load_model\n",
      "    s = _load_bytes(f)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/onnx/__init__.py\", line 34, in _load_bytes\n",
      "    with open(cast(Text, f), 'rb') as readable:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './calculator/calculator_2.onnx'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dimensions , output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dimensions,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = torch.load('./storage/calculator.model')\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1)\n",
    "input_names = [ \"actual_input_1\" ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"./storage/calculator_2.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n",
    "\n",
    "#pip install git+https://github.com/onnx/onnx-tensorflow.git\n",
    "#onnx-tf convert -t tf -i /path/to/input.onnx -o /path/to/output.pb\n",
    "#pip install tensorflow-addons\n",
    "os.system('onnx-tf convert -i ./calculator/calculator_2.onnx -o ./calculator/calculator.pb')\n",
    "\n",
    "# https://medium.com/@pnitsan/exporting-and-running-a-deep-learning-model-in-the-browser-including-lstm-a-straight-forward-574a766ef1d6\n",
    "\n",
    "#tensorflowjs_converter  --input_format=tf_frozen_model --output_node_names='Calculator'  ./calculator.pb ./calculator.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38813fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
