{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0552dbd7",
   "metadata": {},
   "source": [
    "## Machine learning module to multiply by 3\n",
    "\n",
    "- Simple model creation to test out various of Manipulations that are possible to do using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae026a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training f(5) = -2.676\n",
      "epoch 1: w = -0.563538 , loss = 92.551842 , inputs torch.Size([4, 1]) \n",
      "epoch 2501: w = 2.560971 , loss = 0.242266 , inputs torch.Size([4, 1]) \n",
      "epoch 5001: w = 2.636560 , loss = 0.189941 , inputs torch.Size([4, 1]) \n",
      "epoch 7501: w = 2.663431 , loss = 0.163532 , inputs torch.Size([4, 1]) \n",
      "epoch 10001: w = 2.687697 , loss = 0.140802 , inputs torch.Size([4, 1]) \n",
      "epoch 12501: w = 2.710221 , loss = 0.121231 , inputs torch.Size([4, 1]) \n",
      "epoch 15001: w = 2.731101 , loss = 0.104382 , inputs torch.Size([4, 1]) \n",
      "epoch 17501: w = 2.750487 , loss = 0.089875 , inputs torch.Size([4, 1]) \n",
      "epoch 20001: w = 2.768458 , loss = 0.077386 , inputs torch.Size([4, 1]) \n",
      "epoch 22501: w = 2.785142 , loss = 0.066633 , inputs torch.Size([4, 1]) \n",
      "epoch 25001: w = 2.800622 , loss = 0.057374 , inputs torch.Size([4, 1]) \n",
      "epoch 27501: w = 2.814993 , loss = 0.049402 , inputs torch.Size([4, 1]) \n",
      "epoch 30001: w = 2.828352 , loss = 0.042538 , inputs torch.Size([4, 1]) \n",
      "epoch 32501: w = 2.840678 , loss = 0.036631 , inputs torch.Size([4, 1]) \n",
      "epoch 35001: w = 2.852196 , loss = 0.031541 , inputs torch.Size([4, 1]) \n",
      "epoch 37501: w = 2.862806 , loss = 0.027162 , inputs torch.Size([4, 1]) \n",
      "epoch 40001: w = 2.872674 , loss = 0.023391 , inputs torch.Size([4, 1]) \n",
      "epoch 42501: w = 2.881849 , loss = 0.020143 , inputs torch.Size([4, 1]) \n",
      "epoch 45001: w = 2.890363 , loss = 0.017346 , inputs torch.Size([4, 1]) \n",
      "epoch 47501: w = 2.898253 , loss = 0.014938 , inputs torch.Size([4, 1]) \n",
      "epoch 50001: w = 2.905565 , loss = 0.012865 , inputs torch.Size([4, 1]) \n",
      "epoch 52501: w = 2.912349 , loss = 0.011080 , inputs torch.Size([4, 1]) \n",
      "epoch 55001: w = 2.918666 , loss = 0.009541 , inputs torch.Size([4, 1]) \n",
      "epoch 57501: w = 2.924558 , loss = 0.008217 , inputs torch.Size([4, 1]) \n",
      "epoch 60001: w = 2.929953 , loss = 0.007078 , inputs torch.Size([4, 1]) \n",
      "epoch 62501: w = 2.934974 , loss = 0.006096 , inputs torch.Size([4, 1]) \n",
      "epoch 65001: w = 2.939712 , loss = 0.005250 , inputs torch.Size([4, 1]) \n",
      "epoch 67501: w = 2.943974 , loss = 0.004523 , inputs torch.Size([4, 1]) \n",
      "epoch 70001: w = 2.948067 , loss = 0.003894 , inputs torch.Size([4, 1]) \n",
      "epoch 72501: w = 2.951732 , loss = 0.003356 , inputs torch.Size([4, 1]) \n",
      "epoch 75001: w = 2.955279 , loss = 0.002890 , inputs torch.Size([4, 1]) \n",
      "epoch 77501: w = 2.958436 , loss = 0.002489 , inputs torch.Size([4, 1]) \n",
      "epoch 80001: w = 2.961421 , loss = 0.002146 , inputs torch.Size([4, 1]) \n",
      "epoch 82501: w = 2.964234 , loss = 0.001847 , inputs torch.Size([4, 1]) \n",
      "epoch 85001: w = 2.966751 , loss = 0.001592 , inputs torch.Size([4, 1]) \n",
      "epoch 87501: w = 2.969137 , loss = 0.001372 , inputs torch.Size([4, 1]) \n",
      "epoch 90001: w = 2.971415 , loss = 0.001181 , inputs torch.Size([4, 1]) \n",
      "Prediction after training: f(5) = 14.941\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "X = torch.tensor([[1],[2],[3],[4]] , dtype=torch.float32)\n",
    "Y = torch.tensor([[3],[6],[9],[12]] , dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "X_test = torch.tensor([5] , dtype=torch.float32)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dimensions , output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dimensions,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size , output_size)\n",
    "\n",
    "#loss\n",
    "\n",
    "print(f'Prediction before training f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "n_itters = 90095\n",
    "learning_rate = 0.0001\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_itters):\n",
    "    # prediction = foreard pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "\n",
    "    #loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    #gradient dw = gradient(X,Y,y_pred)\n",
    "    l.backward()\n",
    "\n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    #zerro gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        if epoch%2500==0:\n",
    "            print(f'epoch {epoch + 1}: w = {w[0][0].item():3f} , loss = {l:8f} , inputs {X.shape} ')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "torch.save(model,'./storage/calculator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe701bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 multiply by 3 = \n",
      "42\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dimensions , output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dimensions,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "model = torch.load('./storage/calculator.model')\n",
    "model.eval()\n",
    "print('14 multiply by 3 = ')\n",
    "print(f'{model(torch.tensor([float(14)])).item():.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec75619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=open('./storage/in.csv','w')\n",
    "for i in range(0,871):\n",
    "    df.write(str(i) + ',' + str(i * 3))\n",
    "    df.write('\\n')\n",
    "df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c02e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.]) tensor([0.])\n",
      "tensor([[666.],\n",
      "        [729.],\n",
      "        [458.],\n",
      "        [745.],\n",
      "        [457.],\n",
      "        [735.],\n",
      "        [685.],\n",
      "        [599.],\n",
      "        [634.],\n",
      "        [ 29.],\n",
      "        [845.],\n",
      "        [800.]]) tensor([[1998.],\n",
      "        [2187.],\n",
      "        [1374.],\n",
      "        [2235.],\n",
      "        [1371.],\n",
      "        [2205.],\n",
      "        [2055.],\n",
      "        [1797.],\n",
      "        [1902.],\n",
      "        [  87.],\n",
      "        [2535.],\n",
      "        [2400.]])\n",
      "871 218\n",
      "Prediction after training: f(5) = 15.000\n",
      "Prediction after training: f(10) = 30.000\n",
      "Prediction after training: f(1) = 3.000\n",
      "graph(%to_calc : Float(1, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %lin.bias : Float(1, strides=[1], requires_grad=1, device=cpu),\n",
      "      %6 : Float(1, 1, strides=[1, 1], requires_grad=0, device=cpu)):\n",
      "  %4 : Float(1, 1, 1, 1, strides=[1, 1, 1, 1], device=cpu) = onnx::MatMul(%to_calc, %6)\n",
      "  %calculated : Float(1, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%lin.bias, %4) # /opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:1847:0\n",
      "  return (%calculated)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##loss functions with Torch implemented\n",
    "# 1) Designe model (input , output size , forward pass)\n",
    "# 2) Construct Loss and Optimizer\n",
    "# 3) Training loop\n",
    "#   - Forward pass : Compute prediction\n",
    "#   - backward pass : gradients\n",
    "#     - update our weights\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "\n",
    "# 0) prepare data\n",
    "\n",
    "\n",
    "class CalcDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "\n",
    "        X_numpy, Y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "        self.x = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "        self.y = torch.from_numpy(Y_numpy.astype(np.float32))\n",
    "        self.n_samples = self.y.shape[0]\n",
    "\n",
    "        xy = np.loadtxt('./storage/in.csv' , delimiter=\",\",dtype=np.float32)\n",
    "        self.x = torch.from_numpy(xy[:,[0]])\n",
    "        self.y = torch.from_numpy(xy[:,[1]]) # n_samples 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index],self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset = CalcDataset()\n",
    "first_data = dataset[0]\n",
    "features,labels = first_data\n",
    "print(features,labels)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset , batch_size=12 , shuffle=True,num_workers=1)\n",
    "\n",
    "dataitter = iter(dataloader)\n",
    "data = dataitter.next()\n",
    "features,labels = data\n",
    "print(features,labels)\n",
    "\n",
    "# 1)model\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dimensions , output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dimensions,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size , output_size)\n",
    "\n",
    "#2) loss && optimizer\n",
    "learning_rate=0.01\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#def loss(y, y_predicted):\n",
    "#    print(y, y_predicted)\n",
    "#    exit()\n",
    "#    return ((y_predicted - y)**2).mean()\n",
    "#criterion = loss\n",
    "\n",
    "#optimizer = torch.optim.Adadelta(model.parameters() , lr=learning_rate)\n",
    "optimizer = torch.optim.Rprop(model.parameters() , lr=learning_rate) # [best]\n",
    "## fatal optimizer = torch.optim.SparseAdam(model.parameters() , lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters() , lr=learning_rate)\n",
    "\n",
    "#https://en.wikipedia.org/wiki/Rprop\n",
    "\n",
    "#training loop\n",
    "num_epoch = 100\n",
    "total_samples = len(dataset)\n",
    "n_itterations = math.ceil(total_samples/4)\n",
    "\n",
    "print(total_samples,n_itterations)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i , (inputs, labels) in enumerate(dataloader):\n",
    "\n",
    "        # prediction = foreard pass\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        # loss\n",
    "        l = criterion(labels, y_pred)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 150 == 0:\n",
    "            #epoch 5085: w = 2.946607 , loss = 0.004022 , inputs torch.Size([4, 1])\n",
    "            #epoch 2/2 , step 50/218 , inputs torch.Size([12, 1]) , loss =      nan\n",
    "\n",
    "            print(f'epoch {epoch+1}/{num_epoch} , step {i+1}/{n_itterations} , inputs {inputs.shape} , loss = {l:8f}')\n",
    "\n",
    "\n",
    "#plot\n",
    "predicted = model(labels).detach().numpy()\n",
    "\n",
    "\n",
    "X_test = torch.tensor([5] , dtype=torch.float32)\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n",
    "X_test = torch.tensor([10] , dtype=torch.float32)\n",
    "print(f'Prediction after training: f(10) = {model(X_test).item():.3f}')\n",
    "X_test = torch.tensor([1] , dtype=torch.float32)\n",
    "print(f'Prediction after training: f(1) = {model(X_test).item():.3f}')\n",
    "\n",
    "dummy_input = torch.randn(1,1,1,1)\n",
    "input_names = [ \"to_calc\" ]\n",
    "output_names = [ \"calculated\" ]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"storage/calculator_lin.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n",
    "# os.system('onnx-tf convert -i ./calculator.onnx -o ./calculator.pb')\n",
    "#tensorflowjs_converter  ./calculator.pb ./calculator.json\n",
    "\n",
    "plt.plot(inputs.numpy(),labels.numpy() , 'ro')\n",
    "plt.plot(inputs.numpy(),predicted,'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4757b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%actual_input_1 : Float(1)\n",
      "      %1 : Float(1, 1)\n",
      "      %2 : Float(1)) {\n",
      "  %3 : Float(1, 1) = onnx::Transpose[perm=[1, 0]](%1), scope: LinearRegression/Linear[lin]\n",
      "  %4 : Float(1) = onnx::MatMul(%actual_input_1, %3), scope: LinearRegression/Linear[lin]\n",
      "  %output1 : Float(1) = onnx::Add(%4, %2), scope: LinearRegression/Linear[lin]\n",
      "  return (%output1);\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dimensions , output_dim):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dimensions,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = torch.load('calculator.model')\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1)\n",
    "input_names = [ \"actual_input_1\" ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"calculator.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n",
    "\n",
    "#pip install git+https://github.com/onnx/onnx-tensorflow.git\n",
    "#onnx-tf convert -t tf -i /path/to/input.onnx -o /path/to/output.pb\n",
    "#pip install tensorflow-addons\n",
    "os.system('onnx-tf convert -i ./calculator/calculator.onnx -o ./calculator/calculator.pb')\n",
    "\n",
    "# https://medium.com/@pnitsan/exporting-and-running-a-deep-learning-model-in-the-browser-including-lstm-a-straight-forward-574a766ef1d6\n",
    "\n",
    "#tensorflowjs_converter  --input_format=tf_frozen_model --output_node_names='Calculator'  ./calculator.pb ./calculator.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38813fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
